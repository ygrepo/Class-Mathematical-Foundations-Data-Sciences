\begin{Verbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{os}

\PYG{k+kn}{import} \PYG{n+nn}{matplotlib.pyplot} \PYG{k+kn}{as} \PYG{n+nn}{plt}
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k+kn}{as} \PYG{n+nn}{np}


\PYG{k}{def} \PYG{n+nf}{calc\PYGZus{}true\PYGZus{}error}\PYG{p}{(}\PYG{n}{x1}\PYG{p}{,} \PYG{n}{x2}\PYG{p}{):}
    \PYG{l+s+sd}{\PYGZsq{}\PYGZsq{}\PYGZsq{} eigenvecs could converge to u or \PYGZhy{}u \PYGZhy{} both are valid eigvecs.}
\PYG{l+s+sd}{    The function should output the L2 norm of (x1 \PYGZhy{} x2)}
\PYG{l+s+sd}{    If x1 = u and x2 = \PYGZhy{}u, we still want the function to output 0 error\PYGZsq{}\PYGZsq{}\PYGZsq{}}

    \PYG{k}{return} \PYG{n}{np}\PYG{o}{.}\PYG{n}{linalg}\PYG{o}{.}\PYG{n}{norm}\PYG{p}{(}\PYG{n}{x1} \PYG{o}{\PYGZhy{}} \PYG{n}{x2}\PYG{p}{)}

\PYG{k}{def} \PYG{n+nf}{eigen\PYGZus{}iteration}\PYG{p}{(}\PYG{n}{A}\PYG{p}{,} \PYG{n}{x0}\PYG{p}{,} \PYG{n}{alpha}\PYG{p}{,} \PYG{n}{max\PYGZus{}iter}\PYG{o}{=}\PYG{l+m+mi}{50}\PYG{p}{,} \PYG{n}{thresh}\PYG{o}{=}\PYG{l+m+mf}{1e\PYGZhy{}3}\PYG{p}{):}
    \PYG{l+s+sd}{\PYGZsq{}\PYGZsq{}\PYGZsq{}A \PYGZhy{} nxn symmetric matrix}
\PYG{l+s+sd}{       x0 \PYGZhy{} np.array of dimension n which is the starting point}
\PYG{l+s+sd}{       alpha \PYGZhy{} learning rate parameter}
\PYG{l+s+sd}{       max\PYGZus{}iter \PYGZhy{} number of iterations to perform}
\PYG{l+s+sd}{       thresh \PYGZhy{} threshold for stopping iteration}

\PYG{l+s+sd}{       stopping criteria: can stop when ||x[k] \PYGZhy{} x[k\PYGZhy{}1]||\PYGZus{}2 \PYGZlt{}= thresh or when it hits max\PYGZus{}iter}

\PYG{l+s+sd}{       return:}
\PYG{l+s+sd}{       relative\PYGZus{}error: array with ||x[k] \PYGZhy{} x[k\PYGZhy{}1]||\PYGZus{}2}
\PYG{l+s+sd}{       true\PYGZus{}error: array with ||x[k] \PYGZhy{} u\PYGZus{}1 ||\PYGZus{}2 where u\PYGZus{}1 is first eigenvector}
\PYG{l+s+sd}{       \PYGZsq{}\PYGZsq{}\PYGZsq{}}

    \PYG{k}{assert} \PYG{p}{((}\PYG{n}{A}\PYG{o}{.}\PYG{n}{transpose}\PYG{p}{()} \PYG{o}{==} \PYG{n}{A}\PYG{p}{)}\PYG{o}{.}\PYG{n}{all}\PYG{p}{())}  \PYG{c+c1}{\PYGZsh{} asserting A is symmetric}
    \PYG{k}{assert} \PYG{p}{(}\PYG{n}{A}\PYG{o}{.}\PYG{n}{shape}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]} \PYG{o}{==} \PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{x0}\PYG{p}{))}

    \PYG{n}{w}\PYG{p}{,} \PYG{n}{v} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{linalg}\PYG{o}{.}\PYG{n}{eigh}\PYG{p}{(}\PYG{n}{A}\PYG{p}{)}
    \PYG{n}{true\PYGZus{}u1} \PYG{o}{=} \PYG{n}{v}\PYG{p}{[:,} \PYG{l+m+mi}{0}\PYG{p}{]}  \PYG{c+c1}{\PYGZsh{} np array with the first eigenvector of A}
    \PYG{n}{relative\PYGZus{}error} \PYG{o}{=} \PYG{p}{[]}
    \PYG{n}{true\PYGZus{}error} \PYG{o}{=} \PYG{p}{[]}
    \PYG{n}{x\PYGZus{}cur} \PYG{o}{=} \PYG{n}{x0}\PYG{o}{.}\PYG{n}{copy}\PYG{p}{()}
    \PYG{n}{iteration} \PYG{o}{=} \PYG{l+m+mi}{0}
    \PYG{k}{while} \PYG{n+nb+bp}{True}\PYG{p}{:}
        \PYG{n}{x\PYGZus{}next} \PYG{o}{=} \PYG{n}{x\PYGZus{}cur} \PYG{o}{+} \PYG{n}{alpha} \PYG{o}{*} \PYG{n}{np}\PYG{o}{.}\PYG{n}{matmul}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{2} \PYG{o}{*} \PYG{n}{A}\PYG{p}{,} \PYG{n}{x\PYGZus{}cur}\PYG{p}{)}
        \PYG{n}{x\PYGZus{}next} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{divide}\PYG{p}{(}\PYG{n}{x\PYGZus{}next}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{linalg}\PYG{o}{.}\PYG{n}{norm}\PYG{p}{(}\PYG{n}{x\PYGZus{}next}\PYG{p}{))}

        \PYG{k}{if} \PYG{n}{calc\PYGZus{}true\PYGZus{}error}\PYG{p}{(}\PYG{n}{x\PYGZus{}cur}\PYG{p}{,} \PYG{n}{x\PYGZus{}next}\PYG{p}{)} \PYG{o}{\PYGZlt{}=} \PYG{n}{thresh}\PYG{p}{:}
            \PYG{k}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}Convergence in \PYGZob{}\PYGZcb{} iterations, alpha:\PYGZob{}\PYGZcb{},}\PYG{l+s+se}{\PYGZbs{}}
\PYG{l+s+s2}{             init\PYGZus{}point\PYGZus{}norm=\PYGZob{}\PYGZcb{}\PYGZdq{}}\PYG{o}{.}\PYG{n}{format}\PYG{p}{(}\PYG{n}{iteration}\PYG{p}{,} \PYG{n}{alpha}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{linalg}\PYG{o}{.}\PYG{n}{norm}\PYG{p}{(}\PYG{n}{x0}\PYG{p}{)))}
            \PYG{k}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}True u1:\PYGZob{}\PYGZcb{}, computed u1:\PYGZob{}\PYGZcb{}, rel\PYGZus{}error:\PYGZob{}\PYGZcb{}\PYGZdq{}}\PYG{o}{.}\PYG{n}{format}\PYG{p}{(}\PYG{n}{true\PYGZus{}u1}\PYG{p}{,} \PYG{n}{x\PYGZus{}next}\PYG{p}{,} \PYG{n}{calc\PYGZus{}true\PYGZus{}error}\PYG{p}{(}\PYG{n}{x\PYGZus{}cur}\PYG{p}{,} \PYG{n}{x\PYGZus{}next}\PYG{p}{)))}
            \PYG{k}{break}
        \PYG{n}{iteration} \PYG{o}{+=} \PYG{l+m+mi}{1}
        \PYG{k}{if} \PYG{n}{iteration} \PYG{o}{\PYGZgt{}=} \PYG{n}{max\PYGZus{}iter}\PYG{p}{:}
            \PYG{k}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}Maximum iteration exceeded!\PYGZdq{}}\PYG{p}{)}
            \PYG{k}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}True u1:\PYGZob{}\PYGZcb{}, computed u1:\PYGZob{}\PYGZcb{}, rel\PYGZus{}error:\PYGZob{}\PYGZcb{}, alpha:\PYGZob{}\PYGZcb{}\PYGZdq{}}
                  \PYG{o}{.}\PYG{n}{format}\PYG{p}{(}\PYG{n}{true\PYGZus{}u1}\PYG{p}{,} \PYG{n}{x\PYGZus{}next}\PYG{p}{,} \PYG{n}{calc\PYGZus{}true\PYGZus{}error}\PYG{p}{(}\PYG{n}{x\PYGZus{}cur}\PYG{p}{,} \PYG{n}{x\PYGZus{}next}\PYG{p}{),} \PYG{n}{alpha}\PYG{p}{))}
            \PYG{k}{break}
        \PYG{n}{relative\PYGZus{}error}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{n}{calc\PYGZus{}true\PYGZus{}error}\PYG{p}{(}\PYG{n}{x\PYGZus{}cur}\PYG{p}{,} \PYG{n}{x\PYGZus{}next}\PYG{p}{))}
        \PYG{n}{true\PYGZus{}error}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{n}{calc\PYGZus{}true\PYGZus{}error}\PYG{p}{(}\PYG{n}{x\PYGZus{}cur}\PYG{p}{,} \PYG{n}{true\PYGZus{}u1}\PYG{p}{))}
        \PYG{n}{x\PYGZus{}cur} \PYG{o}{=} \PYG{n}{x\PYGZus{}next}

    \PYG{c+c1}{\PYGZsh{}\PYGZsh{} fill in code to do do your projected gradient ascent}
    \PYG{c+c1}{\PYGZsh{}\PYGZsh{} append both the list with the errors}

    \PYG{k}{return} \PYG{n}{relative\PYGZus{}error}\PYG{p}{,} \PYG{n}{true\PYGZus{}error}
\end{Verbatim}
